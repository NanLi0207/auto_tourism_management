# crawler/base_crawler.py
from abc import ABC, abstractmethod
from typing import Any, List, Dict, Optional
import time
import logging

# âœ… åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# å¦‚æœé¡¹ç›®ä¸­æ²¡æœ‰å…¨å±€ logger é…ç½®ï¼Œå¯ä»¥ä¸ºåŸºç¡€çˆ¬è™«æ·»åŠ ç®€å•çš„ StreamHandler
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter("[%(asctime)s] [%(levelname)s] %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)


class BaseCrawler(ABC):
    """
    ğŸ•¸ï¸ BaseCrawler

    æ‰€æœ‰çˆ¬è™«ç±»çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†æœ€æ ¸å¿ƒçš„ä¸‰ä¸ªæ¥å£ï¼š
    - open_page(): æ‰“å¼€ç›®æ ‡é¡µé¢
    - extract_booking_info(): æå–å½“å‰é¡µé¢çš„è®¢å•æ•°æ®
    - go_to_next_page(): ç¿»é¡µ

    å­ç±»éœ€å®ç°ä»¥ä¸ŠæŠ½è±¡æ–¹æ³•ã€‚
    crawl_all_pages() æä¾›äº†ä¸€ä¸ªé€šç”¨çš„ç¿»é¡µ + æ•°æ®é‡‡é›†ä¸»æµç¨‹ã€‚
    """

    def __init__(self, driver: Any, start_date: str, end_date: str):
        """
        åˆå§‹åŒ–åŸºç¡€çˆ¬è™«ç±»ã€‚

        Args:
            driver (Any): Selenium WebDriver å¯¹è±¡ï¼Œç”¨äºæµè§ˆå™¨è‡ªåŠ¨åŒ–æ“ä½œã€‚
        """
        self.start_date = start_date
        self.end_date = end_date
        self.driver = driver

    @abstractmethod
    def open_page(self) -> None:
        """
        æ‰“å¼€ç›®æ ‡é¡µé¢ã€‚

        å­ç±»å¿…é¡»å®ç°è¯¥æ–¹æ³•ï¼Œé€šå¸¸åŒ…æ‹¬ï¼š
        - æ‹¼æ¥ç›®æ ‡ URL
        - è°ƒç”¨ driver.get()
        - ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        """
        pass

    @abstractmethod
    def extract_booking_info(self) -> List[Dict[str, Any]]:
        """
        ä»å½“å‰é¡µé¢æå–è®¢å•ä¿¡æ¯ã€‚

        Returns:
            List[Dict[str, Any]]: å½“å‰é¡µæ‰€æœ‰è®¢å•ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯æ¡è®¢å•ä¸ºä¸€ä¸ªå­—å…¸ã€‚
        """
        pass

    @abstractmethod
    def go_to_next_page(self) -> bool:
        """
        ç‚¹å‡»â€œä¸‹ä¸€é¡µâ€æŒ‰é’®å®ç°ç¿»é¡µã€‚

        Returns:
            bool:
                - True: æˆåŠŸç¿»åˆ°ä¸‹ä¸€é¡µ
                - False: æ²¡æœ‰ä¸‹ä¸€é¡µï¼Œç»“æŸé‡‡é›†
        """
        pass

    def crawl_all_pages(self, delay_between_pages: int = 5) -> List[Dict[str, Any]]:
        """
        é€šç”¨çš„å¤šé¡µçˆ¬å–æµç¨‹ï¼š
        - è°ƒç”¨ extract_booking_info() æŠ“å–å½“å‰é¡µè®¢å•
        - è°ƒç”¨ go_to_next_page() ç¿»é¡µ
        - ç›´åˆ°æ²¡æœ‰ä¸‹ä¸€é¡µä¸ºæ­¢

        Args:
            delay_between_pages (int): ç¿»é¡µä¹‹é—´çš„ç­‰å¾…æ—¶é—´ï¼Œå•ä½ç§’ã€‚

        Returns:
            List[Dict[str, Any]]: æ‰€æœ‰é¡µé¢é‡‡é›†çš„è®¢å•æ•°æ®ã€‚
        """
        all_orders = []
        page_num = 1
        self.open_page()
        while True:
            logger.info(f"ğŸ“„ æ­£åœ¨å¤„ç†ç¬¬ {page_num} é¡µ...")
            try:
                page_orders = self.extract_booking_info()
                order_count = len(page_orders) if page_orders else 0
                logger.info(f"âœ… æŠ“å– {order_count} æ¡è®¢å•")
                all_orders.extend(page_orders or [])
            except Exception as e:
                logger.error(f"âŒ ç¬¬ {page_num} é¡µé‡‡é›†å¤±è´¥: {e}", exc_info=True)
                break
            # ç¿»é¡µ
            if not self.go_to_next_page():
                logger.info("ğŸ æ²¡æœ‰ä¸‹ä¸€é¡µäº†ï¼Œé‡‡é›†ç»“æŸã€‚")
                break

            page_num += 1
            time.sleep(delay_between_pages)

        logger.info(f"ğŸ“Š å…±é‡‡é›† {len(all_orders)} æ¡è®¢å•")
        return all_orders
